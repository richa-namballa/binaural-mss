{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b188785c-c947-4fbd-be16-3ac4c20bd739",
   "metadata": {},
   "source": [
    "# $\\Delta$ITD and $\\Delta$ILD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c0e69d-8657-4f07-abfb-5a12a7696e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from scipy.fft import rfft, irfft\n",
    "from sklearn.utils.extmath import weighted_mode\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55665e17-05b7-4d40-9e9d-ef5135f3cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "SAMPLE_RATE = 44100\n",
    "ENERGY_THRESHOLD = 5e-4\n",
    "TMAX = int(1e-3 * SAMPLE_RATE)  # maximum lag in samples = +/- 1 ms\n",
    "FRAME_LENGTH = 0.5  # seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff453693-d631-453b-839b-4ba3c913c93a",
   "metadata": {},
   "source": [
    "## Evaluation Functions\n",
    "\n",
    "Adapted from [`https://github.com/vb000/SemanticHearing/blob/main/src/helpers/eval_utils.py`](https://github.com/vb000/SemanticHearing/blob/main/src/helpers/eval_utils.py)\n",
    "\n",
    "Veluri, B., Itani, M., Chan, J., Yoshioka, T., & Gollakota, S. (2023). Semantic hearing: Programming acoustic scenes with binaural hearables. In _Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology_ (pp. 1-15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28e46d1-68a1-4471-91ae-86fa6c39353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tdoa(x1, x2, interp=1, fs=44100, phat=True, t_max=None):\n",
    "    \"\"\"\n",
    "    This function computes the time difference of arrival (TDOA)\n",
    "    of the signal at the two ears or microphones. We recover tau\n",
    "    using the Generalized Cross Correlation - Phase Transform (GCC-PHAT)\n",
    "    method.\n",
    "    \n",
    "    Knapp, C., & Carter, G. C. (1976). The generalized correlation method for\n",
    "    estimation of time delay.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x1 : (1d-array) the signal of the reference microphone\n",
    "    x2 : (1d-array) the signal of the second microphone\n",
    "    interp : (int) optional (default 1), the interpolation value\n",
    "             for the cross-correlation, it can improve the\n",
    "             timeresolution (and hence DOA resolution)\n",
    "    fs : (int), optional (default 44100 Hz), the sampling frequency\n",
    "          of the input signal\n",
    "    phat : (bool) whether to use phase transform normalization\n",
    "    t_max : (int) the maximum tau (lag) to use\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    tdoa : (float), the delay between the two microphones (in seconds)\n",
    "    \"\"\"\n",
    "    # zero padded length for the FFT\n",
    "    n = x1.shape[-1] + x2.shape[-1] - 1\n",
    "    if n % 2 != 0:\n",
    "        n += 1\n",
    "\n",
    "    # Generalized Cross Correlation Phase Transform\n",
    "    # used to find the delay between the two microphones\n",
    "    X1 = rfft(np.array(x1, dtype=np.float32), n=n, axis=-1)\n",
    "    X2 = rfft(np.array(x2, dtype=np.float32), n=n, axis=-1)\n",
    "\n",
    "    if phat:\n",
    "        X1 /= np.abs(X1) + 1e-15  # added epsilon to avoid division error\n",
    "        X2 /= np.abs(X2) + 1e-15  # added epsilon to avoid division error\n",
    "\n",
    "    cc = irfft(X1 * np.conj(X2), n=interp * n, axis=-1)\n",
    "\n",
    "    # alternative: compute phase spectrum first and then normalize\n",
    "    # R = X1 * np.conj(X2)\n",
    "    # R_phat = R / (np.abs(R) + 1e-15)\n",
    "    # cc = irfft(R_phat, n=interp * n, axis=-1)\n",
    "\n",
    "    # maximum possible delay given distance between microphones\n",
    "    if t_max is None:\n",
    "        t_max = n // 2 + 1\n",
    "\n",
    "    # reorder the cross-correlation coefficients\n",
    "    cc = np.concatenate((cc[..., -t_max:], cc[..., :t_max]), axis=-1)\n",
    "\n",
    "    # pick max cross correlation index as delay\n",
    "    tau = np.argmax(np.abs(cc), axis=-1)\n",
    "    tau -= t_max  # because zero time is at the center of the array\n",
    "\n",
    "    return tau / (fs * interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a8545-9493-418d-beff-cdbdb38b5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ild(s_left, s_right):\n",
    "    \"\"\"\n",
    "    Compute the interaural level (intensity) difference (ILD)\n",
    "    between the left and right ears.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s_left : (1d-array) the signal of the left ear\n",
    "    s_right : (1d-array) the signal of the right ear\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    ild : (float) interaural level difference, in decibels (dB)\n",
    "    \"\"\"\n",
    "    sum_sq_left = np.sum(s_left ** 2, axis=-1)\n",
    "    sum_sq_right = np.sum(s_right ** 2, axis=-1)\n",
    "    \n",
    "    return 10 * np.log10(sum_sq_left / sum_sq_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe3ff8-fa0b-44c3-9b47-ba46f1cd741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def framewise_gccphat(x, frame_dur, sr, window='tukey'):\n",
    "    \"\"\"\n",
    "    Compute the TDOA using the GCC-PHAT algorithm, in\n",
    "    a frame-wise manner.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : (2d-array) the binaural signal\n",
    "    frame_dur : (float) length of frame (in seconds)\n",
    "    sr : (int) sample rate of signal\n",
    "    window : (str) type of window to apply to each frame\n",
    "              using scipy window functions\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    itd : (float) interaural time difference, in seconds\n",
    "    \"\"\"\n",
    "    frame_width = int(frame_dur * sr)\n",
    "\n",
    "    # total number of frames T\n",
    "    T = (x.shape[-1]) // frame_width\n",
    "\n",
    "    # drop samples to get a multiple of frame size\n",
    "    if x.shape[-1] % T != 0:\n",
    "        x = x[..., :(frame_width * T)]\n",
    "    \n",
    "    assert x.shape[-1] % T == 0\n",
    "\n",
    "    # split into frames\n",
    "    frames = np.array(np.split(x, T, axis=-1))\n",
    "\n",
    "    # apply window\n",
    "    window = signal.get_window(window, frame_width)\n",
    "    frames = frames * window\n",
    "\n",
    "    # consider only frames that have energy above some threshold (ignore silence)\n",
    "    frame_energy = np.max(np.mean(frames**2, axis=-1)**0.5, axis=-1)\n",
    "    mask = frame_energy > ENERGY_THRESHOLD\n",
    "    frames = frames[mask]\n",
    "\n",
    "    # compute TDOA by frame\n",
    "    fw_gccphat = tdoa(frames[..., 0, :], frames[..., 1, :], fs=sr, t_max=TMAX)\n",
    "\n",
    "    # apply weighted mode to get single ITD value\n",
    "    itd = weighted_mode(fw_gccphat, frame_energy[mask], axis=-1)[0]\n",
    "\n",
    "    return itd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce0bc1-4d81-4e81-adef-39e2b8b938ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fw_itd_diff(s_est, s_gt, sr, frame_duration=0.25):\n",
    "    \"\"\"\n",
    "    Computes the ITD error between the signal estimated\n",
    "    by the model and the ground truth signal using the\n",
    "    frame-wise GCC-PHAT algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s_est : (2d-array) the estimated signal\n",
    "    s_gt : (2d-array) the ground-truth signal\n",
    "    sr : (int) sample rate of signal\n",
    "    frame_duration : (float), optional (default 0.25 s),\n",
    "                     length of frame (in seconds)\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    itd : (float) delta ITD between estimated and \n",
    "          ground-truth signals, in microseconds   \n",
    "    \"\"\"\n",
    "    itd_gt = framewise_gccphat(s_gt, frame_duration, sr) * 1e6\n",
    "    itd_est = framewise_gccphat(s_est, frame_duration, sr) * 1e6\n",
    "    return np.abs(itd_est - itd_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4b552-1594-46dd-8b0f-07faff142745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ild_diff(s_est, s_gt):\n",
    "    \"\"\"\n",
    "    Computes the ILD error between the signal estimated\n",
    "    by the model and the ground truth signal.\n",
    "\n",
    "        Parameters\n",
    "    ----------\n",
    "    s_est : (2d-array) the estimated signal\n",
    "    s_gt : (2d-array) the ground-truth signal\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    ild : (float) delta ILD between estimated and \n",
    "          ground-truth signals, in decibels (dB)  \n",
    "    \"\"\"\n",
    "    ild_est = compute_ild(s_est[..., 0, :], s_est[..., 1, :])\n",
    "    ild_gt = compute_ild(s_gt[..., 0, :], s_gt[..., 1, :])\n",
    "    return np.abs(ild_est - ild_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f058973-df47-40de-b141-99b81f08c2f8",
   "metadata": {},
   "source": [
    "### Low Frequency Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cee000-abe3-4fdd-9b1f-5cb7395a905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 200\n",
    "sr = 44100\n",
    "N = sr * 5\n",
    "time_vector = np.linspace(0, 5, num=N)\n",
    "channel_1 = np.sin(f0 * time_vector)\n",
    "delay = int(0.001 * sr)  # 1000 microseconds\n",
    "channel_2 = np.pad(channel_1, (delay, 0))[:N]\n",
    "y = np.stack((channel_1, channel_2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f9840e-4f17-48d5-ba34-8bd113cec5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ITD with 0.25 s frames: {framewise_gccphat(y, 0.25, sr) * 1e6}\")\n",
    "print(f\"ITD with 0.5 s frames: {framewise_gccphat(y, 0.5, sr) * 1e6}\")\n",
    "print(f\"ITD with 1 s frames: {framewise_gccphat(y, 1, sr) * 1e6}\")\n",
    "print(f\"ILD: {compute_ild(channel_1, 3 * channel_2)} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd0260-9de7-49ab-9027-ad83cffa4f88",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff43a148-0afa-4163-9e73-5138ef055aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE =  datetime.now().strftime(\"%Y-%m-%d\")\n",
    "MODEL = '' # htdemucs_ft, spleeter, umxhq\n",
    "EVAL_DIR = \"../data/eval/interaural/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c95abda-6649-40a9-a686-36e60ee477e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEMS = [\"drums\", \"bass\", \"other\", \"vocals\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cb3322-eb3d-476e-a25b-dfa5e23247ee",
   "metadata": {},
   "source": [
    "### Stereo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6cff7-0902-4498-9fca-0ddc82461920",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'stereo'\n",
    "\n",
    "# set input and output directories\n",
    "REFERENCE_DIR = f\"../data/musdb18hq/test/\"\n",
    "ESTIMATE_DIR = f\"../data/output/{MODEL}/{DATASET}/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d1cefe-6e71-4650-a543-1816bff5facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output directory if it does not already exist\n",
    "print(\"Creating evaluation directory, if it does not already exist...\")\n",
    "os.makedirs(EVAL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b289b-5413-4592-b4f1-aba63c092ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the files in the input directory\n",
    "print(\"Loading list of files...\")\n",
    "song_list = [f for f in os.listdir(REFERENCE_DIR) if os.path.isdir(os.path.join(REFERENCE_DIR, f))]\n",
    "print(f\"There are {len(song_list)} files in the reference directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1cd41-32a3-418b-94d4-9ed3874456d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "source_list = []\n",
    "itd_list = []\n",
    "ild_list = []\n",
    "\n",
    "print(\"Beginning to evaluate stems...\")\n",
    "for source in STEMS:\n",
    "    print(f\"\\n>>>>{source} <<<<\")\n",
    "    for song in tqdm(song_list):\n",
    "        \n",
    "        ref_file = os.path.join(REFERENCE_DIR, song, f\"{source}.wav\")\n",
    "        est_file = os.path.join(ESTIMATE_DIR, song, f\"{source}.wav\")\n",
    "\n",
    "        # load reference and estimate stems\n",
    "        y_ref, sr_ref = sf.read(ref_file)\n",
    "        y_est, sr_est = sf.read(est_file)\n",
    "\n",
    "        # check sample rates\n",
    "        assert sr_ref == sr_est == SAMPLE_RATE\n",
    "\n",
    "        # calculate Delta ITD\n",
    "        delta_itd = fw_itd_diff(y_est.T, y_ref.T, SAMPLE_RATE, FRAME_LENGTH)\n",
    "\n",
    "        # calculate ILD\n",
    "        delta_ild = ild_diff(y_est.T, y_ref.T)\n",
    "\n",
    "        title_list.append(song)\n",
    "        source_list.append(source)\n",
    "        itd_list.append(delta_itd)\n",
    "        ild_list.append(delta_ild)\n",
    "\n",
    "results_df = pd.DataFrame({\"title\": title_list, \"source\": source_list,\n",
    "                           \"diff_ITD\": itd_list, \"diff_ILD\": ild_list})\n",
    "\n",
    "print(\"Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616e4b4-96e3-46e0-b102-384964d119ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort\n",
    "results_df.sort_values(by=['title', 'source'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f2172-ceab-417d-9f58-b32a9e7ce498",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(EVAL_DIR, f'interaural_{DATE}_{MODEL}_{DATASET}.csv')\n",
    "\n",
    "results_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57770685-f3c2-47fb-9f3e-6400fb823eb2",
   "metadata": {},
   "source": [
    "### Binaural Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f53744-5bf6-46d2-9947-ea46b128d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'binaural'\n",
    "\n",
    "# set input and output directories\n",
    "REFERENCE_DIR = f\"../data/binaural_musdb18/test/\"\n",
    "ESTIMATE_DIR = f\"../data/output/{MODEL}/{DATASET}/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fce913-4eae-45eb-9d5b-076337a32994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output directory if it does not already exist\n",
    "print(\"Creating evaluation directory, if it does not already exist...\")\n",
    "os.makedirs(EVAL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ecad6-b9c4-4f67-821b-46b8a91639eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the files in the input directory\n",
    "print(\"Loading list of files...\")\n",
    "song_list = [f for f in os.listdir(REFERENCE_DIR) if os.path.isdir(os.path.join(REFERENCE_DIR, f))]\n",
    "print(f\"There are {len(song_list)} files in the reference directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dc13e-dd79-4cbd-bdf3-2f8b3902697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "source_list = []\n",
    "itd_list = []\n",
    "ild_list = []\n",
    "\n",
    "print(\"Beginning to evaluate stems...\")\n",
    "for source in STEMS:\n",
    "    print(f\"\\n>>>>{source} <<<<\")\n",
    "    for song in tqdm(song_list):\n",
    "        \n",
    "        ref_file = os.path.join(REFERENCE_DIR, song, f\"{source}.wav\")\n",
    "        est_file = os.path.join(ESTIMATE_DIR, song, f\"{source}.wav\")\n",
    "\n",
    "        # load reference and estimate stems\n",
    "        y_ref, sr_ref = sf.read(ref_file)\n",
    "        y_est, sr_est = sf.read(est_file)\n",
    "\n",
    "        # check sample rates\n",
    "        assert sr_ref == sr_est\n",
    "\n",
    "        # calculate Delta ITD\n",
    "        delta_itd = fw_itd_diff(y_est.T, y_ref.T, sr_ref, FRAME_LENGTH)\n",
    "\n",
    "        # calculate ILD\n",
    "        delta_ild = ild_diff(y_est.T, y_ref.T)\n",
    "\n",
    "        title_list.append(song)\n",
    "        source_list.append(source)\n",
    "        itd_list.append(delta_itd)\n",
    "        ild_list.append(delta_ild)\n",
    "\n",
    "results_df = pd.DataFrame({\"title\": title_list, \"source\": source_list,\n",
    "                           \"diff_ITD\": itd_list, \"diff_ILD\": ild_list})\n",
    "\n",
    "print(\"Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c91f65e-dd9d-46b5-90a8-6dacc7f23789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort\n",
    "results_df.sort_values(by=['title', 'source'], inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3996f-0c0a-436d-b642-cc74a09ed3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(EVAL_DIR, f'interaural_{DATE}_{MODEL}_{DATASET}.csv')\n",
    "\n",
    "results_df.to_csv(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
