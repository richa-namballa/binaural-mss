{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a479a8c5-d4f9-4997-b120-04abef904c80",
   "metadata": {},
   "source": [
    "# Open-Unmix Separation\n",
    "\n",
    "Note: this notebook must be run on a CUDA-enabled device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c1c88-aadc-4641-89e8-8fc1c304e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import openunmix\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e2554-c76f-40b9-82e6-e8a205c2255f",
   "metadata": {},
   "source": [
    "### Separation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617e587-72da-4efa-8814-48899147f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate(in_file, model, gpu=True):\n",
    "    \"\"\"\n",
    "    Run Open-Unmix source separation model on WAV files to isolate stems.\n",
    "\n",
    "    :param in_file: (str) path of mixture WAV file to separate\n",
    "    :param model: (Separator) open unmix model object\n",
    "    :param gpu: (bool) whether a gpu is available for use\n",
    "    \"\"\"\n",
    "    # only process wav files\n",
    "    if in_file.endswith(\".wav\"):\n",
    "        # read the soundfile\n",
    "        y, sr = sf.read(in_file)\n",
    "\n",
    "        num_samples, num_channels = y.shape\n",
    "      \n",
    "        if gpu:\n",
    "            # send model to gpu\n",
    "            model.to('cuda')\n",
    "            \n",
    "            # convert to 3 dimensional tensor (1, num_channels, num_samples)\n",
    "            x = torch.from_numpy(y.T.reshape(1, num_channels, num_samples).astype(np.float32)).to('cuda')\n",
    "            with torch.no_grad():\n",
    "                out = model(x)\n",
    "\n",
    "            out_stems = []\n",
    "            for i in range(len(STEMS)):\n",
    "                est_stem = out[0][i].cpu().detach().numpy()  # convert to numpy array\n",
    "                est_stem[np.isnan(est_stem)] = 0  # convert nan to 0\n",
    "                out_stems.append(est_stem)\n",
    "        else:\n",
    "            print(\"Please enable CUDA for inference.\")\n",
    "\n",
    "    else:\n",
    "        out_stems = None\n",
    "        print(\"Invalid input file type. Please use WAV files only.\")\n",
    "\n",
    "    return out_stems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d17282-348e-4eff-9a10-169bc1562c18",
   "metadata": {},
   "source": [
    "### Separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc9ace-51b0-42b1-b752-70045e4d68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEMS = [\"vocals\", \"drums\", \"bass\", \"other\"]\n",
    "SAMPLE_RATE = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9665a8a-23fb-4ab0-af76-8176f2ac09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "MODEL = openunmix.umxhq() # torch.hub.load('sigsep/open-unmix-pytorch', 'umxhq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313645f-b1b1-4113-87f8-f41ec9698a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert MODEL.sample_rate == SAMPLE_RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffef6c9-d2ce-45a7-813b-53122e74279a",
   "metadata": {},
   "source": [
    "#### Stereo Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17216c9e-2eac-43c6-801e-498659dbecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input and output directories\n",
    "INPUT_DIR = \"../data/musdb18hq/test/\"\n",
    "OUTPUT_DIR = \"../data/output/umxhq/stereo/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69026b14-9b42-4487-96bd-3e5e526886d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the files in the input directory\n",
    "print(\"Loading list of files...\")\n",
    "file_list = [f for f in os.listdir(INPUT_DIR) if os.path.isdir(os.path.join(INPUT_DIR, f))]\n",
    "print(f\"There are {len(file_list)} files in the input directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e160883-2df6-452c-a015-e74db84bfd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output directory if it does not already exist\n",
    "print(\"Creating output directory, if it does not already exist...\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d508f-3bc9-45f5-9daf-6bb6975080e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each file\n",
    "print(\"Beginning to process files...\")\n",
    "for file in tqdm(file_list):\n",
    "    out_dir = os.path.join(OUTPUT_DIR, file)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out = separate(os.path.join(INPUT_DIR, file, 'mixture.wav'), MODEL)\n",
    "    for i in range(len(STEMS)):\n",
    "        out_path = os.path.join(out_dir, STEMS[i] + '.wav')\n",
    "        sf.write(out_path, out[i].T, SAMPLE_RATE)  # transpose so it is (num_samples, num_channels)\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f657b4f8-f525-41c6-97f8-f6ac99340a62",
   "metadata": {},
   "source": [
    "#### Binaural Mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5e848-d83a-469a-927d-3ab794e9522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set input and output directories\n",
    "INPUT_DIR = \"../data/binaural_musdb18/test/\"\n",
    "OUTPUT_DIR = \"../data/output/umxhq/binaural/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d616a-9773-4567-9a6a-35a4de9c0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all of the files in the input directory\n",
    "print(\"Loading list of files...\")\n",
    "file_list = [f for f in os.listdir(INPUT_DIR) if os.path.isdir(os.path.join(INPUT_DIR, f))]\n",
    "print(f\"There are {len(file_list)} files in the input directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f301b9-5854-41f3-809a-60defd54ce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the output directory if it does not already exist\n",
    "print(\"Creating output directory, if it does not already exist...\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cd5afb-d6ef-4068-b102-a34d93b742b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through each file\n",
    "print(\"Beginning to process files...\")\n",
    "for file in tqdm(file_list):\n",
    "    out_dir = os.path.join(OUTPUT_DIR, file)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out = separate(os.path.join(INPUT_DIR, file, 'mixture.wav'), MODEL)\n",
    "    for i in range(len(STEMS)):\n",
    "        out_path = os.path.join(out_dir, STEMS[i] + '.wav')\n",
    "        sf.write(out_path, out[i].T, SAMPLE_RATE)  # transpose so it is (num_samples, num_channels)\n",
    "print(\"Processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
